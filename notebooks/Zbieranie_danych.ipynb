{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException, TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrolling_and_cleacking(driver_):\n",
    "    wait = WebDriverWait(driver_, 10)\n",
    "\n",
    "    try:\n",
    "    # Oczekiwanie na pojawienie się przycisku \"Akceptuj\" i kliknięcie go\n",
    "        akceptuj_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button#onetrust-accept-btn-handler')))\n",
    "        akceptuj_button.click()\n",
    "    except Exception as e:\n",
    "        print(\"Nie udało się znaleźć lub kliknąć przycisku 'Akceptuj':\", e)\n",
    "\n",
    "    wait = WebDriverWait(driver_, 10)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "        # Sprawdzenie, czy przycisk \"Pokaż kolejne oferty\" nadal jest obecny na stronie\n",
    "            load_more_button = wait.until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'button.tw-btn.tw-btn-primary.tw-px-8.tw-block.tw-btn-xl'))\n",
    "            )\n",
    "        # Przewinięcie do przycisku i kliknięcie go\n",
    "            driver_.execute_script(\"arguments[0].scrollIntoView();\", load_more_button)\n",
    "            time.sleep(2)\n",
    "            load_more_button.click()\n",
    "            print(\"Kliknięto\")\n",
    "            time.sleep(2)\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            print(\"Nie można już znaleźć przycisku 'Pokaż kolejne oferty'. Zakończenie.\")\n",
    "            break\n",
    "        except ElementClickInterceptedException:\n",
    "            driver_.execute_script(\"window.scrollBy(0, 100);\")\n",
    "            time.sleep(2)\n",
    "\n",
    "    wait = WebDriverWait(driver_, 10)\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'nfj-postings-list')))\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.tw-mr-2 [data-cy^=\"salary \"]')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offer_salary_info(offer_):\n",
    "    salary_element = offer_.select_one('[class=\"tw-mb-0\"]')\n",
    "    salary_text = salary_element.text.strip().replace('\\xa0', '')\n",
    "    if salary_text != \"Sprawdź SalaryMatch\":\n",
    "        salary_info = {\n",
    "        'low': salary_text.split(\" \")[0],\n",
    "        'high': salary_text.split(\" \")[3],\n",
    "        'currency': salary_text.split(\" \")[-1]\n",
    "        }\n",
    "    else:\n",
    "            salary_info = \"Brak widełki\"\n",
    "    \n",
    "    return salary_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offer_location_info(offer_soup_):\n",
    "    translate_city = {\n",
    "    \"Warsaw\": \"Warszawa\",\n",
    "    \"Wroclove\": \"Wrocław\",\n",
    "    \"Krakow\": \"Kraków\",\n",
    "    \"Cracow\": \"Kraków\",\n",
    "    \"Gdansk\": \"Gdańsk\",\n",
    "    \"Poznan\": \"Poznań\",\n",
    "    \"Lodz\": \"Łódź\",\n",
    "    \"Bialystok\": \"Białystok\"\n",
    "    }\n",
    "    if offer_soup_.select_one(\"[commondatacyclick]\").text.strip() == \"Praca zdalna\":\n",
    "        location_info = \"Praca zdalna\"\n",
    "    elif len(offer_soup_.select('a span[class=\"ng-star-inserted\"]')) == 1:\n",
    "        location = offer_soup_.select_one('a span[class=\"ng-star-inserted\"]').text.strip()\n",
    "        location_info = translate_city.get(location, location)\n",
    "    else:\n",
    "        locations = [element.text.strip() for element in offer_soup_.select('a span[class=\"ng-star-inserted\"]')]\n",
    "        translated_locations = list({translate_city.get(location, location) for location in locations})\n",
    "        location_info = translated_locations if len(translated_locations) > 1 else translated_locations[0]\n",
    "    return location_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def necessery_technology(offer_soup_):\n",
    "    technology_info = [element.text.strip() for element in offer_soup_.select('[data-cy=\"JobOffer_Category\"], [branch=\"musts\"] span.ng-star-inserted, li[_ngcontent-serverapp-c1062005900].tw-btn.tw-btn-xs.tw-text-sm.tw-font-normal.tw-text-teal.tw-border-2.tw-border-teal.text-truncate.ng-star-inserted')]\n",
    "    return technology_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_to_have_technology(offer_soup_):\n",
    "    if offer_soup_.select_one('#posting-nice-to-have') != None:\n",
    "        nice_to_have_info = [element.text.strip() for element in offer_soup_.select('#posting-nice-to-have [id*=\"item-tag\"]')]\n",
    "    else: \n",
    "        nice_to_have_info = \"Brak\"\n",
    "    return nice_to_have_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience(offer_soup_):\n",
    "    if offer_soup_.select_one('#posting-seniority span') != None:\n",
    "        experience_level_info = offer_soup_.select_one('#posting-seniority span').text.strip()\n",
    "    else: \n",
    "        experience_level_info = \"Brak\"\n",
    "    return experience_level_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offer_exists(offer, records):\n",
    "    categories = [\"data analyst\", \"data scientist\", \"data engineer\"]\n",
    "    for category in categories:\n",
    "        if category in records:\n",
    "            for existing_offer in records[category]:\n",
    "                if (existing_offer['name'] == offer['name'] and\n",
    "                    existing_offer['company'] == offer['company'] and\n",
    "                    existing_offer['experience level'] == offer['experience level'] and\n",
    "                    existing_offer['technology'] == offer['technology'] and\n",
    "                    existing_offer['nice to have'] == offer['nice to have'] and\n",
    "                    existing_offer['location'] == offer['location'] and\n",
    "                    existing_offer['salary'] == offer['salary']):\n",
    "                    return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kliknięto\n",
      "Kliknięto\n",
      "Kliknięto\n",
      "Kliknięto\n",
      "Nie można już znaleźć przycisku 'Pokaż kolejne oferty'. Zakończenie.\n",
      "Nie można już znaleźć przycisku 'Pokaż kolejne oferty'. Zakończenie.\n",
      "Kliknięto\n",
      "Kliknięto\n",
      "Nie można już znaleźć przycisku 'Pokaż kolejne oferty'. Zakończenie.\n"
     ]
    }
   ],
   "source": [
    "job_titels = [\"analyst\", \"scientist\", \"engineer\"]\n",
    "records = {}\n",
    "offers = []\n",
    "\n",
    "\n",
    "for title in job_titels:\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://link_to_a_job_search_website_data%20{stanowisko}%27\".replace(\"{stanowisko}\", title))\n",
    "\n",
    "    scrolling_and_cleacking(driver)\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    for section in soup.select('nfj-postings-list')[:2]:\n",
    "        for offer in section.select('.posting-list-item'):\n",
    "            offer_link = offer.get('href')\n",
    "            offer_page = requests.get(f\"https://link_to_a_job_search_website{offer_link}\")\n",
    "            offer_soup = BeautifulSoup(offer_page.text, \"html.parser\")                    \n",
    "\n",
    "            new_offer = {\n",
    "            'name': offer.select_one(\"h3.posting-title__position\").text.strip(),\n",
    "            'company': offer.select_one(\"h4.company-name\").text.strip(),\n",
    "            'experience level': experience(offer_soup),\n",
    "            'technology': necessery_technology(offer_soup),\n",
    "            'nice to have': nice_to_have_technology(offer_soup),\n",
    "            'location': offer_location_info(offer_soup),\n",
    "            'salary': offer_salary_info(offer)\n",
    "            }\n",
    "\n",
    "            if not offer_exists(new_offer, records):\n",
    "                offers.append(new_offer)\n",
    "\n",
    "    records[\"data \" + title] = offers\n",
    "    offers = []\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisanie do json\n",
    "\n",
    "path = os.path.join(\"..\", \"data\", \"interim\")\n",
    "current_date = datetime.today().strftime('%Y_%m_%d')\n",
    "with open(os.path.join(path,f'job offers {current_date}.json'), 'w', encoding='utf-8') as file:\n",
    "    json.dump(records, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  name             company experience level  \\\n",
      "0                         Data Analyst                 XTB              Mid   \n",
      "1                     Data Analyst CRM          Connectis_           Junior   \n",
      "2  Customer Master Data Senior Analyst   Devire Sp. z o.o.           Senior   \n",
      "3                         Data analyst            Uncapped              Mid   \n",
      "4                  Senior Data Analyst  Brainly Sp. z o.o.           Senior   \n",
      "\n",
      "                                          technology  \\\n",
      "0  [Data, Python, SQL, Data base, Polski, Angielski]   \n",
      "1           [Data, CRM, Python, SQL, Angielski (B2)]   \n",
      "2  [Data, T-SQL, SAP, Excel, Communication skills...   \n",
      "3  [Data, SQL, Problem solving, Critical thinking...   \n",
      "4  [Data, SQL, Google Analytics, Tableau, BigQuer...   \n",
      "\n",
      "                                        nice to have      location  \\\n",
      "0      [Microsoft Azure, Databricks, Spark, PySpark]  Praca zdalna   \n",
      "1                                               Brak  Praca zdalna   \n",
      "2                                               Brak  Praca zdalna   \n",
      "3               [Python, BigQuery, Proactivity, GCP]      Warszawa   \n",
      "4  [Python, Google Tag Manager, Amplitude, Snowfl...  Praca zdalna   \n",
      "\n",
      "       category salary_low salary_high salary_currency salary  \n",
      "0  data analyst      11760       18480             PLN    NaN  \n",
      "1  data analyst      17000       21000             PLN    NaN  \n",
      "2  data analyst      25200       33600             PLN    NaN  \n",
      "3  data analyst      10000       16000             PLN    NaN  \n",
      "4  data analyst      17000       23000             PLN    NaN  \n",
      "Saved all job offers to: ..\\data\\interim\\job_offers_2024_07_07.csv\n"
     ]
    }
   ],
   "source": [
    "# Zapisanie do CSV\n",
    "all_records = []\n",
    "\n",
    "for category, values in records.items():\n",
    "    for record in values:\n",
    "        record['category'] = category\n",
    "        all_records.append(record)\n",
    "\n",
    "df = pd.json_normalize(all_records, sep='_')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "path = os.path.join(\"..\", \"data\", \"interim\")\n",
    "\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "current_date = datetime.today().strftime('%Y_%m_%d')\n",
    "filename = os.path.join(path, f\"job_offers_{current_date}.csv\")\n",
    "df.to_csv(filename, sep=';', encoding='utf-8', index=False)\n",
    "\n",
    "print(f\"Saved all job offers to: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
